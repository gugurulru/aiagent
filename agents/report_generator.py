# agents/pdf_report_generator.py
from typing import Dict, List, Optional, Tuple
from datetime import datetime
import os
import json
import re

from reportlab.lib.pagesizes import A4
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib.units import mm
from reportlab.platypus import (
    SimpleDocTemplate, Paragraph, Spacer, PageBreak, Table, TableStyle,
    Flowable, KeepTogether
)
from reportlab.lib import colors
from reportlab.lib.enums import TA_LEFT, TA_CENTER, TA_JUSTIFY
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont

from reportlab.graphics.shapes import Drawing
from reportlab.graphics.charts.barcharts import VerticalBarChart

# ---- Open LLM (OpenAI SDK v1) ----
try:
    from openai import OpenAI
    _OPENAI_AVAILABLE = True
except Exception:
    _OPENAI_AVAILABLE = False

from state_schema import PipelineState


# ===================== ìœ í‹¸ =====================

def _safe_get(d: dict, path: List, default=None):
    cur = d
    for p in path:
        if isinstance(cur, dict) and p in cur:
            cur = cur[p]
        else:
            return default
    return cur

def _fmt_float(x: Optional[float], digits: int = 2):
    if x is None:
        return "-"
    try:
        return f"{x:.{digits}f}"
    except Exception:
        return "-"

def _nn(x, default="-"):
    return x if (x is not None and x != "") else default

def _wrap(s: str, width: int = 110):
    # ê°•ì œ ì¤„ë°”ê¿ˆì€ ReportLab Paragraphê°€ ì²˜ë¦¬(CJK wrap)
    return s or ""

def _grade_color(grade: str) -> colors.Color:
    g = (grade or "").upper()
    if g in ("A+", "A"):
        return colors.HexColor("#27ae60")
    if g == "B":
        return colors.HexColor("#f39c12")
    if g in ("C", "D"):
        return colors.HexColor("#e74c3c")
    return colors.HexColor("#7f8c8d")

def _risk_color(level: str) -> str:
    m = {"CRITICAL": "#e74c3c", "HIGH": "#e67e22", "MEDIUM": "#f1c40f", "LOW": "#2ecc71", "UNKNOWN": "#7f8c8d"}
    return m.get((level or "").upper(), "#7f8c8d")

def _severity_emoji(sev: str) -> str:
    m = {"critical": "ğŸ”´", "high": "ğŸŸ ", "medium": "ğŸŸ¡", "low": "ğŸŸ¢"}
    return m.get((sev or "").lower(), "âšª")


class HRLine(Flowable):
    """ìˆ˜í‰ ë¼ì¸ êµ¬ë¶„ì"""
    def __init__(self, width=450, thickness=0.5, color=colors.HexColor("#bdc3c7")):
        Flowable.__init__(self)
        self.width = width
        self.thickness = thickness
        self.color = color
    def draw(self):
        self.canv.saveState()
        self.canv.setStrokeColor(self.color)
        self.canv.setLineWidth(self.thickness)
        self.canv.line(0, 0, self.width, 0)
        self.canv.restoreState()


# ======== LLM ì¶œë ¥ ì •ë¦¬ ========

def _sanitize_markdown_headers(text: str) -> str:
    if not text:
        return ""
    t = re.sub(r"^#{1,6}\s*", "", text, flags=re.MULTILINE)
    t = re.sub(r"\*\*(.*?)\*\*", r"\1", t)
    t = t.replace("â€”", "-").replace("â€“", "-").replace("|", "")
    return t.strip()

def _split_to_paragraphs(text: str) -> List[str]:
    if not text:
        return []
    lines = text.splitlines()
    paras: List[str] = []
    buf: List[str] = []
    bullet_re = re.compile(r"^\s*(?:[-â€¢]|\d+\.)\s+")
    for ln in lines:
        ln = ln.rstrip()
        if not ln:
            if buf:
                paras.append(" ".join(buf).strip())
                buf = []
            continue
        if bullet_re.match(ln):
            if buf:
                paras.append(" ".join(buf).strip())
                buf = []
            paras.append(ln.strip())
        else:
            buf.append(ln.strip())
    if buf:
        paras.append(" ".join(buf).strip())
    return paras

def _render_llm_text(text: str, styles: Dict) -> List[Flowable]:
    flows: List[Flowable] = []
    text = _sanitize_markdown_headers(text)
    paras = _split_to_paragraphs(text)
    bullet_re = re.compile(r"^\s*(?:[-â€¢]|\d+\.)\s+(.*)$")
    for p in paras:
        m = bullet_re.match(p)
        if m:
            flows.append(Paragraph(f"â€¢ {m.group(1)}", styles["KBullet"]))
        else:
            flows.append(Paragraph(_wrap(p, 120), styles["KBody"]))
    return flows


# ===================== ë©”ì¸ í´ë˜ìŠ¤ =====================

class PDFReportGenerator:
    """
    - CJK ì¤„ë°”ê¿ˆ ì ìš©(ë¬¸ì¥ ì¤‘ê°„ ì˜ë¦¼ ë°©ì§€)
    - TOC í•­ëª© ê¸€ì í¬ê²Œ(KTOCItem)
    - Appendix 5.3 'í‰ê°€ ê¸°ì¤€ ì¶œì²˜' (í˜ì´ì§€ ì •ë³´ í¬í•¨)
    - Appendix 5.4 'RAG íŠ¸ë ˆì´ìŠ¤(ê²€ìƒ‰ ì¿¼ë¦¬ & ê·¼ê±° í˜ì´ì§€)' ì¶”ê°€
      Â· state["criteria_rag_traces"] (êµ¬ì¡°í™”) ë˜ëŠ” state["criteria_rag_log_text"] (ì›ë¬¸ ë¡œê·¸) ì‚¬ìš©
    """

    def __init__(self, model_name: Optional[str] = None):
        self.korean_font = "Helvetica"  # fallback
        self._setup_korean_fonts()
        self.model_name = model_name or os.getenv("LLM_MODEL", "gpt-4o-mini")
        self.client = None
        if _OPENAI_AVAILABLE and os.getenv("OPENAI_API_KEY"):
            try:
                self.client = OpenAI()
            except Exception:
                self.client = None

    # ---------- Font ----------
    def _setup_korean_fonts(self):
        try:
            font_paths = [
                "/usr/share/fonts/truetype/noto/NotoSansKR-Regular.ttf",
                "/usr/share/fonts/opentype/noto/NotoSansCJKkr-Regular.otf",
                "C:\\Windows\\Fonts\\malgun.ttf",
                "/System/Library/Fonts/AppleSDGothicNeo.ttc",
            ]
            for fp in font_paths:
                if os.path.exists(fp):
                    pdfmetrics.registerFont(TTFont("KoreanFont", fp))
                    self.korean_font = "KoreanFont"
                    print(f"âœ… í•œê¸€ í°íŠ¸ ë¡œë“œ ì™„ë£Œ: {fp}")
                    return
            print("âš ï¸ í•œê¸€ í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Helvetica ì‚¬ìš©")
        except Exception as e:
            print(f"âš ï¸ í°íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")

    # ---------- Styles ----------
    def _create_styles(self) -> Dict:
        styles = getSampleStyleSheet()
        font = self.korean_font
        styles.add(ParagraphStyle(
            name="KTitle",
            parent=styles["Heading1"],
            fontName=font,
            fontSize=22,
            textColor=colors.HexColor("#2c3e50"),
            spaceAfter=14,
            alignment=TA_LEFT,
            wordWrap='CJK',
        ))
        styles.add(ParagraphStyle(
            name="KSubTitle",
            parent=styles["Heading2"],
            fontName=font,
            fontSize=15,
            textColor=colors.HexColor("#34495e"),
            spaceBefore=12,
            spaceAfter=10,
            wordWrap='CJK',
        ))
        styles.add(ParagraphStyle(
            name="KHead3",
            parent=styles["Heading3"],
            fontName=font,
            fontSize=12.5,
            textColor=colors.HexColor("#2c3e50"),
            spaceBefore=8,
            spaceAfter=6,
            wordWrap='CJK',
        ))
        styles.add(ParagraphStyle(
            name="KBody",
            parent=styles["BodyText"],
            fontName=font,
            fontSize=10.3,
            leading=15.6,
            alignment=TA_JUSTIFY,
            spaceAfter=4,
            wordWrap='CJK',
        ))
        styles.add(ParagraphStyle(
            name="KBullet",
            parent=styles["BodyText"],
            fontName=font,
            fontSize=10.3,
            leading=14.2,
            leftIndent=14,
            spaceAfter=2,
            wordWrap='CJK',
        ))
        styles.add(ParagraphStyle(
            name="KMeta",
            parent=styles["BodyText"],
            fontName=font,
            fontSize=9.3,
            textColor=colors.HexColor("#7f8c8d"),
            leading=13.5,
            spaceAfter=3,
            wordWrap='CJK',
        ))
        styles.add(ParagraphStyle(  # í‘œ ì…€ìš©
            name="KCell",
            parent=styles["BodyText"],
            fontName=font,
            fontSize=9.5,
            leading=13.0,
            alignment=TA_LEFT,
            wordWrap='CJK',
        ))
        styles.add(ParagraphStyle(  # TOC í•­ëª© í¬ê²Œ
            name="KTOCItem",
            parent=styles["BodyText"],
            fontName=font,
            fontSize=13.5,
            leading=18.0,
            alignment=TA_LEFT,
            wordWrap='CJK',
        ))
        return styles

    # ---------- Header / Footer ----------
    def _header_footer(self, canvas, doc, company_name, domain, created_str):
        canvas.saveState()
        w, h = A4
        canvas.setFont(self.korean_font, 9)
        canvas.setFillColor(colors.HexColor("#7f8c8d"))
        canvas.drawString(20*mm, h - 12*mm, f"{company_name} Â· {domain} Â· ìƒì„±ì¼ {created_str}")
        page_num = canvas.getPageNumber()
        canvas.setFillColor(colors.HexColor("#95a5a6"))
        canvas.drawRightString(w - 20*mm, 12*mm, f"{page_num}")
        canvas.restoreState()

    # ---------- LLM ----------
    def _compose_llm_context(self, state: PipelineState, derived_risk: str) -> str:
        payload = {
            "company_name": state.get("company_name"),
            "domain": state.get("domain"),
            "ethics_score": state.get("ethics_score", {}),
            "ethics_evaluation": {
                k: {
                    "score": _safe_get(state, ["ethics_evaluation", k, "score"], 0),
                    "confidence": _safe_get(state, ["ethics_evaluation", k, "confidence"], 0.0),
                    "strengths": _safe_get(state, ["ethics_evaluation", k, "strengths"], []),
                    "issues": _safe_get(state, ["ethics_evaluation", k, "issues"], []),
                    "evidence": [
                        {
                            "finding": e.get("finding"),
                            "source": e.get("source"),
                            "tier": e.get("tier"),
                            "reliability": e.get("reliability"),
                            "type": e.get("evidence_type"),
                            "weight": e.get("weight"),
                            "url": e.get("url")
                        } for e in _safe_get(state, ["ethics_evaluation", k, "evidence"], [])[:6]
                    ]
                } for k in ["transparency", "human_oversight", "data_governance", "accuracy_validation", "accountability"]
            },
            "risk_level_resolved": derived_risk,
            "critical_issues": [
                {
                    "severity": x.get("severity"),
                    "category": x.get("category"),
                    "description": x.get("description"),
                    "recommendation": x.get("recommendation"),
                    "eu_ai_act_article": x.get("eu_ai_act_article"),
                    "evidence_quality": x.get("evidence_quality")
                } for x in state.get("critical_issues", [])[:8]
            ],
            "analysis_result": {
                "summary": _safe_get(state, ["analysis_result", "summary"], ""),
                "business_model": _safe_get(state, ["analysis_result", "business_model"], ""),
                "target_users": _safe_get(state, ["analysis_result", "target_users"], [])[:6],
                "technology_stack": _safe_get(state, ["analysis_result", "technology_stack"], [])[:10],
            }
        }
        return json.dumps(payload, ensure_ascii=False)

    def _llm_generate(self, system_prompt: str, user_prompt: str, max_tokens: int = 800) -> str:
        if not self.client:
            return ""
        try:
            resp = self.client.chat.completions.create(
                model=self.model_name,
                temperature=0.25,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt},
                ],
                max_tokens=max_tokens,
            )
            return (resp.choices[0].message.content or "").strip()
        except Exception as e:
            print(f"âš ï¸ LLM í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return ""

    def _resolve_risk_level(self, state: PipelineState) -> str:
        current = _safe_get(state, ["final_scores", "risk_level"], "UNKNOWN") or "UNKNOWN"
        if current and current.upper() != "UNKNOWN":
            return current
        if not self.client:
            return "UNKNOWN"
        sys_p = (
            "ì—­í• : EU AI Act ë§¥ë½ì—ì„œ ì‹œìŠ¤í…œ/ë„ë©”ì¸ì˜ ìœ„í—˜êµ°ì„ ì¶”ì •í•˜ëŠ” ë¶„ì„ê°€.\n"
            "ê·œì¹™: ì…ë ¥ JSONì˜ ë„ë©”ì¸/ìš”ì•½/ëŒ€ìƒìœ ì €/ê¸°ìˆ ë§Œ ì‚¬ìš©. ì™¸ë¶€ ì§€ì‹ ì¶”ê°€ ê¸ˆì§€. "
            "ì¶œë ¥ì€ CRITICAL/HIGH/MEDIUM/LOW ì¤‘ í•˜ë‚˜ì˜ ëŒ€ë¬¸ì í† í°ë§Œ.\n"
            "ë¯¼ê° ë¶„ì•¼(ì˜ë£ŒÂ·êµìœ¡Â·ê³ ìš©Â·ê³µê³µì•ˆì „ ë“±)ëŠ” ë³´ìˆ˜ì ìœ¼ë¡œ HIGH ì´ìƒ."
        )
        user_p = json.dumps({
            "domain": state.get("domain"),
            "analysis_hint": {
                "summary": _safe_get(state, ["analysis_result", "summary"], ""),
                "business_model": _safe_get(state, ["analysis_result", "business_model"], ""),
                "target_users": _safe_get(state, ["analysis_result", "target_users"], [])[:6],
            }
        }, ensure_ascii=False)
        out = self._llm_generate(sys_p, user_p, max_tokens=5).upper().strip()
        return out if out in {"CRITICAL", "HIGH", "MEDIUM", "LOW"} else "UNKNOWN"

    # ---------- Public ----------
    def execute(self, state: PipelineState) -> PipelineState:
        print("\n" + "="*70)
        print("ğŸ“„ [PDF ë³´ê³ ì„œ ìƒì„± Agent] ì‹œì‘ (TOC í™•ëŒ€ & ì¶œì²˜ + RAG íŠ¸ë ˆì´ìŠ¤ í¬í•¨)")
        print("="*70)

        try:
            filename = f"ethics_report_{state['company_name']}_{state['domain']}_{datetime.now().strftime('%Y%m%d')}.pdf"
            print(f"ğŸ“ PDF ìƒì„± ì¤‘: {filename}")
            self._generate_pdf(state, filename)
            state["report_path"] = filename
            print("\n" + "="*70)
            print("âœ… PDF ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ!")
            print("="*70 + f"\nğŸ“ íŒŒì¼: {filename}")
        except Exception as e:
            import traceback
            print(f"âŒ PDF ìƒì„± ì‹¤íŒ¨: {e}")
            state["errors"].append({
                "stage": "pdf_generation",
                "error": str(e),
                "timestamp": datetime.now().isoformat(),
                "recovered": False,
                "traceback": traceback.format_exc(),
                "impact_on_reliability": "medium"
            })
        return state

    # ---------- Build ----------
    def _generate_pdf(self, state: PipelineState, filename: str):
        company = _nn(state.get("company_name"))
        domain = _nn(state.get("domain"))
        created_str = datetime.now().strftime("%Y-%m-%d %H:%M")

        doc = SimpleDocTemplate(
            filename, pagesize=A4,
            rightMargin=20*mm, leftMargin=20*mm,
            topMargin=22*mm, bottomMargin=18*mm
        )
        styles = self._create_styles()
        story: List = []

        # ìœ„í—˜ë“±ê¸‰ LLM ë³´ì •
        derived_risk = self._resolve_risk_level(state)

        # 1) Cover
        story.extend(self._cover_page(state, styles))
        story.append(PageBreak())

        # 2) TOC (í•­ëª© í°íŠ¸ í¬ê²Œ)
        story.extend(self._toc(styles))
        story.append(PageBreak())

        # 3) Executive Summary
        story.extend(self._executive_summary_with_llm(state, styles, derived_risk))
        story.append(PageBreak())

        # 4) Ethics
        story.extend(self._ethics_section_with_llm(state, styles, derived_risk))
        story.append(PageBreak())

        # 5) Final Score & Reco
        story.extend(self._final_scores_and_llm_reco(state, styles, derived_risk))
        story.append(PageBreak())

        # 6) References
        story.extend(self._references(state, styles))
        story.append(PageBreak())

        # 7) Appendix
        story.extend(self._appendix(state, styles))

        doc.build(
            story,
            onFirstPage=lambda c, d: self._header_footer(c, d, company, domain, created_str),
            onLaterPages=lambda c, d: self._header_footer(c, d, company, domain, created_str)
        )
        print(f"âœ… PDF íŒŒì¼ ìƒì„± ì™„ë£Œ: {filename}")

    # ---------- Sections ----------
    def _cover_page(self, state: PipelineState, styles: Dict) -> List:
        s: List = []
        s.append(Spacer(1, 25*mm))
        s.append(Paragraph("EU AI Act", ParagraphStyle(
            name="BigTitleLine1", parent=styles["KTitle"], fontSize=26, alignment=TA_CENTER, spaceAfter=10*mm, wordWrap='CJK'
        )))
        s.append(Paragraph("ìœ¤ë¦¬ ìœ„í—˜ì„± í‰ê°€ ë³´ê³ ì„œ", ParagraphStyle(
            name="BigTitleLine2", parent=styles["KTitle"], fontSize=22, alignment=TA_CENTER, spaceAfter=12*mm, wordWrap='CJK'
        )))

        info = [
            ["ëŒ€ìƒ ê¸°ì—…", _nn(state.get("company_name"))],
            ["ë„ë©”ì¸", _nn(state.get("domain"))],
            ["í‰ê°€ ì¼ì‹œ", datetime.now().strftime("%Yë…„ %mì›” %dì¼ %H:%M")],
            ["ë³´ê³ ì„œ ID", _nn(state.get("run_id"), "-")[:16]],
        ]
        s.append(self._table(info, [55*mm, 100*mm], head=False))
        s.append(Spacer(1, 8*mm))

        es = state.get("ethics_score", {})
        total = es.get("total", 0)
        grade = es.get("grade", "N/A")
        score_data = [
            ["í•­ëª©", "ê°’"],
            ["ì¢…í•© ì ìˆ˜(ìœ¤ë¦¬)", f"{total}/100"],
            ["ìµœì¢… ë“±ê¸‰(ìœ¤ë¦¬)", grade],
        ]
        s.append(self._table(score_data, [55*mm, 100*mm], head=True,
                             emphasize=[(1,1)], emphasize_color=_grade_color(grade)))
        return s

    def _toc(self, styles: Dict) -> List:
        s: List = []
        s.append(Paragraph("ëª©ì°¨", ParagraphStyle(
            name="TOCTitle", parent=styles["KTitle"], alignment=TA_LEFT, wordWrap='CJK'
        )))
        s.append(Spacer(1, 6*mm))
        items = [
            "1. Executive Summary",
            "2. Ethics Evaluation (EU AI Act)",
            "3. Final Score & Recommendations",
            "4. References",
            "5. Appendix",
        ]
        for it in items:
            s.append(Paragraph(it, styles["KTOCItem"]))  # í¬ê²Œ
        return s

    # ====== Executive Summary ======
    def _executive_summary_with_llm(self, state: PipelineState, styles: Dict, derived_risk: str) -> List:
        s: List = []
        s.append(Paragraph("1. Executive Summary", styles["KTitle"]))
        s.append(HRLine()); s.append(Spacer(1, 3*mm))

        web_cnt = _safe_get(state, ["web_collection", "count"], 0) or 0
        sp_cnt = _safe_get(state, ["specialized_collection", "count"], 0) or 0
        s.append(Paragraph(
            f"ë³¸ í‰ê°€ëŠ” ìˆ˜ì§‘ëœ ë¬¸ì„œ(Web {web_cnt}ê±´, Specialized {sp_cnt}ê±´)ë¥¼ ë°”íƒ•ìœ¼ë¡œ "
            "ê°„ì ‘ ì§€í‘œë¥¼ ì¶”ì •í•˜ì—¬ EU AI Act ì¤€ìˆ˜ ìˆ˜ì¤€ì„ í‰ê°€í–ˆìŠµë‹ˆë‹¤.",
            styles["KMeta"]
        ))
        s.append(Spacer(1, 2*mm))

        es = state.get("ethics_score", {})
        rows = [
            ["ìµœì¢… ì¢…í•© ì ìˆ˜(ìœ¤ë¦¬)", f"{es.get('total', 0)}/100"],
            ["ìµœì¢… ë“±ê¸‰(ìœ¤ë¦¬ ê¸°ì¤€)", _nn(es.get("grade", "N/A"))],
            ["ìœ„í—˜ ë“±ê¸‰(ë„ë©”ì¸/RAG)", _nn(derived_risk)],
        ]
        summary_tbl = self._table([["í•­ëª©", "ê°’"], *rows], [65*mm, 90*mm], head=True)
        summary_tbl.splitByRow = 1
        s.append(KeepTogether([summary_tbl]))
        s.append(Spacer(1, 4*mm))

        context = self._compose_llm_context(state, derived_risk)
        system_prompt = (
            "ì—­í• : EU AI Act ìœ¤ë¦¬í‰ê°€ Executive Summary ì‘ì„±ì.\n"
            "ì œì•½: ì…ë ¥ JSON(ìœ¤ë¦¬ ì ìˆ˜/ì¹´í…Œê³ ë¦¬ ì¦ê±°/ìœ„í—˜ë“±ê¸‰)ë§Œ ì‚¬ìš©. ì™¸ë¶€ ì§€ì‹ ê¸ˆì§€.\n"
            "ìŠ¤íƒ€ì¼: í•œêµ­ì–´, ëª…í™•í•œ ì¤„ë°”ê¿ˆ, ê° ë¶ˆë¦¿ 1ë¬¸ì¥, ì´ 120~220ë‹¨ì–´ ë‚´.\n"
            "í’ˆì§ˆ: ê·¼ê±°ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì–¸ê¸‰(ì˜ˆ: ì§ì ‘ì¦ê±°/Tier, ì ìˆ˜/ì´ìŠˆ)."
        )
        user_prompt = (
            "ë‹¤ìŒ STATE_JSONì„ ê·¼ê±°ë¡œ ì‘ì„±:\n"
            "â‘  ì²« ë¬¸ë‹¨: ëŒ€ìƒ/ë„ë©”ì¸ + ìœ¤ë¦¬ ì¢…í•© ì ìˆ˜/ë“±ê¸‰ í•µì‹¬ ê²°ë¡ (2~3ë¬¸ì¥)\n"
            "â‘¡ ê·¼ê±° ê¸°ë°˜ í•˜ì´ë¼ì´íŠ¸ 3~5ê°œ(ê° 1ë¬¸ì¥, ì¦ê±° ì†ì„± ê´„í˜¸ í‘œê¸°)\n"
            "â‘¢ ë¶€ì¡±í•œ ì /ë¦¬ìŠ¤í¬ 3~5ê°œ(ê° 1ë¬¸ì¥, ê´€ë ¨ ì¹´í…Œê³ ë¦¬ ëª…ì‹œ)\n"
            "â‘£ ë§ˆì§€ë§‰ ë¬¸ì¥: RAG ë„ë©”ì¸ ìœ„í—˜ë“±ê¸‰ì˜ ì˜ë¯¸ 1ë¬¸ì¥\n"
            f"\n# STATE_JSON\n{context}"
        )
        llm_text = self._llm_generate(system_prompt, user_prompt, max_tokens=700)
        for flow in _render_llm_text(llm_text, styles):
            s.append(flow)
        return s

    # ====== ìœ¤ë¦¬í‰ê°€(+ LLM ì½”ë©˜íŠ¸, ê·¼ê±° ìŠ¤íƒí˜•) ======
    def _ethics_section_with_llm(self, state: PipelineState, styles: Dict, derived_risk: str) -> List:
        s: List = []
        s.append(Paragraph("2. Ethics Evaluation (EU AI Act)", styles["KTitle"]))
        s.append(HRLine()); s.append(Spacer(1, 3*mm))

        es = state.get("ethics_score", {})
        ev = state.get("ethics_evaluation", {})

        cats = ["transparency", "human_oversight", "data_governance", "accuracy_validation", "accountability"]
        cat_names_en = ["Transparency", "Oversight", "Data", "Accuracy", "Accountability"]
        cat_scores = [int(es.get(c, 0)) for c in cats]

        s.append(Paragraph("Category Scores", styles["KHead3"]))
        s.append(self._bar_chart(cat_names_en, cat_scores, height=160))
        s.append(Spacer(1, 2*mm))

        context = self._compose_llm_context(state, derived_risk)
        system_prompt = (
            "ì—­í• : EU AI Act ìœ¤ë¦¬ ì¹´í…Œê³ ë¦¬ í•´ì„¤ì.\n"
            "ì œì•½: ì…ë ¥ JSONë§Œ ì‚¬ìš©, ì™¸ë¶€ ì§€ì‹ ê¸ˆì§€. í•œêµ­ì–´. í—¤ë”ë¬¸ë²•/í‘œ ê¸ˆì§€. ê° ë¶ˆë¦¿=1ë¬¸ì¥. ì´ 150~260ë‹¨ì–´.\n"
            "ìš”êµ¬: ê°•ì /ë¶€ì¡±/ê°œì„  ìš°ì„ ìˆœìœ„ë¥¼ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì œì‹œí•˜ê³ , ì¦ê±° íƒ€ì…(ì§ì ‘/ê°„ì ‘)ê³¼ tierë¥¼ ê´„í˜¸ë¡œ í‘œì‹œ."
        )
        user_prompt = (
            "STATE_JSONì„ ë°”íƒ•ìœ¼ë¡œ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì‘ì„±:\n"
            "â€¢ íˆ¬ëª…ì„±: ê°•ì  2~3, ë¶€ì¡± 2~3, ê°œì„  1~3(High/Med/Low)\n"
            "â€¢ ì¸ê°„ê°ë…: ë™ì¼\n"
            "â€¢ ë°ì´í„°ê±°ë²„ë„ŒìŠ¤: ë™ì¼\n"
            "â€¢ ì •í™•ë„ê²€ì¦: ë™ì¼\n"
            "â€¢ ì±…ì„ì„±: ë™ì¼\n"
            f"\n# STATE_JSON\n{context}"
        )
        llm_cmt = self._llm_generate(system_prompt, user_prompt, max_tokens=900)
        for flow in _render_llm_text(llm_cmt, styles):
            s.append(flow)

        for idx, key in enumerate(cats):
            cat = ev.get(key, {})
            if not cat:
                continue
            header = Paragraph(f"{idx+1}. {cat_names_en[idx]}", styles["KSubTitle"])
            rows1 = [
                ["ì ìˆ˜", str(cat.get("score", 0))],
                ["ë ˆë²¨", str(cat.get("level", 0))],
            ]
            tbl1 = self._table([["í•­ëª©","ê°’"], *rows1], [65*mm, 90*mm], head=True)
            s.append(KeepTogether([header, tbl1, Spacer(1, 2*mm)]))

            rows2 = [
                ["ê·¼ê±° ìˆ˜(ì§ì ‘/Tier1)", f"{cat.get('evidence_count',0)} / {cat.get('direct_evidence_count',0)} / {cat.get('tier1_evidence_count',0)}"],
                ["ì •ë³´ ê°€ìš©ì„±", _nn(cat.get("information_availability","none"))],
            ]
            tbl2 = self._table([["í•­ëª©","ê°’"], *rows2], [65*mm, 90*mm], head=True)
            s.append(KeepTogether([tbl2, Spacer(1, 2*mm)]))

            if cat.get("strengths"):
                s.append(Paragraph("Strengths", styles["KHead3"]))
                for st in cat["strengths"][:4]:
                    s.append(Paragraph(_wrap(f"â€¢ {st}", 120), styles["KBullet"]))
            if cat.get("issues"):
                s.append(Paragraph("Issues", styles["KHead3"]))
                for it in cat["issues"][:4]:
                    s.append(Paragraph(_wrap(f"â€¢ {it}", 120), styles["KBullet"]))

            evid_list = cat.get("evidence") or []
            if evid_list:
                s.append(Paragraph("Key Evidence", styles["KHead3"]))
                for evi in evid_list[:4]:
                    finding = _wrap(_nn(evi.get("finding")), 110)
                    src = _nn(evi.get("source"))
                    tier = _nn(evi.get("tier"))
                    etype = _nn(evi.get("evidence_type"))
                    rel = _nn(evi.get("reliability"))
                    wgt = _fmt_float(evi.get("weight"))
                    meta = f"ì¶œì²˜: {src} Â· Tier: {tier} Â· íƒ€ì…: {etype} Â· ì‹ ë¢°ì„±: {rel} Â· ê°€ì¤‘ì¹˜: {wgt}"
                    block = [Paragraph(f"â€¢ {finding}", styles["KBody"]),
                             Paragraph(meta, styles["KMeta"]),
                             Spacer(1, 1*mm)]
                    s.append(KeepTogether(block))
            s.append(Spacer(1, 3*mm))
        return s

    # ====== ìµœì¢… ì ìˆ˜ & ê¶Œê³  ======
    def _final_scores_and_llm_reco(self, state: PipelineState, styles: Dict, derived_risk: str) -> List:
        s: List = []
        s.append(Paragraph("3. Final Score & Recommendations", styles["KTitle"]))
        s.append(HRLine()); s.append(Spacer(1, 3*mm))

        es = state.get("ethics_score", {})
        risk_color = _risk_color(derived_risk)
        rows = [
            ["ì¢…í•© ì ìˆ˜(ìœ¤ë¦¬)", f"{es.get('total', 0)}/100"],
            ["ìµœì¢… ë“±ê¸‰(ìœ¤ë¦¬ ê¸°ì¤€)", _nn(es.get("grade", "N/A"))],
            ["ìœ„í—˜ ë“±ê¸‰(ë„ë©”ì¸/RAG)", _nn(derived_risk)],
        ]
        s.append(self._table([["í•­ëª©","ê°’"], *rows], [65*mm, 90*mm], head=True))
        s.append(Spacer(1, 2*mm))
        s.append(Paragraph(
            f'<font color="{risk_color}">â€» ìœ„í—˜ ë“±ê¸‰ì€ ë„ë©”ì¸ íŠ¹ì„±ê³¼ ìš©ë„ë¥¼ RAG/LLMìœ¼ë¡œ í•´ì„í•´ ì¶”ì •í•œ ê°’ì´ë©°, ìœ¤ë¦¬ ì ìˆ˜ì™€ëŠ” ë³„ê°œ ì¶•ì…ë‹ˆë‹¤.</font>',
            styles["KBody"]
        ))

        context = self._compose_llm_context(state, derived_risk)
        system_prompt = (
            "ì—­í• : EU AI Act ì¤€ìˆ˜/ìœ¤ë¦¬ ë¦¬ìŠ¤í¬ ì™„í™”ë¥¼ ìœ„í•œ ê¶Œê³ ì•ˆ ì‘ì„±ì.\n"
            "ì œì•½: ì…ë ¥ JSONë§Œ ì‚¬ìš©. í•œêµ­ì–´. ê° í•­ëª© 1~2ë¬¸ì¥. ì´ 6~10ê°œ ê¶Œê³ . "
            "ê° í•­ëª©ì— [ìš°ì„ ìˆœìœ„]ì™€ (ë‹´ë‹¹ë¶€ì„œ) í‘œê¸°, ë§ˆì§€ë§‰ ì¤„ì— 'ê·¼ê±°:' 1ì¤„."
        )
        user_prompt = (
            "STATE_JSONì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ì„±:\n"
            "â€¢ [High] ë°ì´í„° ê±°ë²„ë„ŒìŠ¤ í‘œì¤€í™”(ë‹´ë‹¹: ë°ì´í„° ê±°ë²„ë„ŒìŠ¤íŒ€) â€“ 1~2ë¬¸ì¥ ì„¤ëª…\n"
            "  ê·¼ê±°: ê´€ë ¨ ì¹´í…Œê³ ë¦¬/í•µì‹¬ ì¦ê±° ìš”ì•½ 1ì¤„\n"
            "â€¢ [Medium] â€¦\n"
            f"\n# STATE_JSON\n{context}"
        )
        llm_reco = self._llm_generate(system_prompt, user_prompt, max_tokens=900)
        for flow in _render_llm_text(llm_reco, styles):
            s.append(flow)
        return s

    # ====== References: ìŠ¤íƒí˜• í•­ëª© ======
    def _references(self, state: PipelineState, styles: Dict) -> List:
        s: List = []
        s.append(Paragraph("4. References", styles["KTitle"]))
        s.append(HRLine()); s.append(Spacer(1, 3*mm))

        all_docs = []
        all_docs += state.get("merged_documents", [])
        all_docs += state.get("web_collection", {}).get("documents", [])
        all_docs += state.get("specialized_collection", {}).get("documents", [])

        by_tier: Dict[str, List[dict]] = {"tier1": [], "tier2": [], "tier3": []}
        for d in all_docs:
            tier = d.get("evidence_tier") or d.get("tier") or "tier3"
            by_tier.setdefault(tier, [])
            by_tier[tier].append(d)

        tier_title = {
            "tier1": "Tier 1 (ìµœê³  ì‹ ë¢°ë„)",
            "tier2": "Tier 2 (ë†’ì€ ì‹ ë¢°ë„)",
            "tier3": "Tier 3 (ë³´í†µ ì‹ ë¢°ë„)"
        }

        for tier_name in ["tier1", "tier2", "tier3"]:
            docs = by_tier.get(tier_name, [])
            if not docs:
                continue
            s.append(Paragraph(tier_title[tier_name], styles["KSubTitle"]))
            for d in docs[:30]:
                title = _wrap(_nn(d.get("title")), 105)
                meta = f"ë°œí–‰ì²˜: {_nn(d.get('publisher','-'))} Â· ì¹´í…Œê³ ë¦¬: {_nn(d.get('source_category','-'))} Â· ë‚ ì§œ: {_nn(d.get('date','-'))}"
                url = _wrap(_nn(d.get("url")), 105)
                block = [
                    Paragraph(f"â€¢ {title}", styles["KBody"]),
                    Paragraph(meta, styles["KMeta"]),
                    Paragraph(url, styles["KMeta"]),
                    Spacer(1, 1*mm)
                ]
                s.append(KeepTogether(block))
            s.append(Spacer(1, 2*mm))
        return s

    # ====== Appendix (ìš”ì•½ í‘œ + í‰ê°€ ê¸°ì¤€ ìƒì„¸ + ì¶œì²˜ + RAG íŠ¸ë ˆì´ìŠ¤) ======
    def _appendix(self, state: PipelineState, styles: Dict) -> List:
        def _cell(text) -> Paragraph:
            return Paragraph(_nn(text), styles["KCell"])

        s: List = []
        s.append(Paragraph("5. Appendix", styles["KTitle"]))
        s.append(HRLine()); s.append(Spacer(1, 3*mm))

        crit = state.get("ethics_evaluation_criteria", {})
        categories = [
            ("transparency", "Transparency"),
            ("human_oversight", "Human Oversight"),
            ("data_governance", "Data Governance"),
            ("accuracy_validation", "Accuracy & Validation"),
            ("accountability", "Accountability"),
        ]

        # --- 5.1 Summary Table ---
        header = [_cell("ë¶„ë¥˜"), _cell("ê¸°ì¤€ìˆ˜"), _cell("í‰ê· ê°€ì¤‘"), _cell("ì˜ˆì‹œ")]
        rows = [header]
        for key, name in categories:
            c = _safe_get(crit, ["categories", key], {})
            items = c.get("criteria", []) if isinstance(c, dict) else []
            cnt = len(items)
            if cnt > 0:
                weights = [float(it.get("weight", 0) or 0) for it in items]
                avg_w = sum(weights) / len(weights) if weights else 0.0
                ex_titles = [str(it.get("title") or "-") for it in items[:2]]
                examples = ", ".join(ex_titles)
            else:
                avg_w = 0.0
                examples = "-"
            rows.append([
                _cell(name),
                _cell(str(cnt)),
                _cell(_fmt_float(avg_w, 2)),
                _cell(examples),
            ])

        summary_tbl = self._table(rows, [40*mm, 18*mm, 22*mm, 80*mm], head=True)
        summary_tbl.splitByRow = 1
        s.append(KeepTogether([Paragraph("5.1 Criteria Summary", styles["KSubTitle"]),
                               summary_tbl,
                               Spacer(1, 3*mm)]))

        # --- 5.2 ìƒì„¸ í•­ëª© ---
        if crit:
            s.append(Paragraph("5.2 í‰ê°€ ê¸°ì¤€ ìƒì„¸", styles["KSubTitle"]))
            for key, name in categories:
                c = _safe_get(crit, ["categories", key], {})
                if not c:
                    continue
                s.append(Paragraph(name, styles["KHead3"]))
                for i, it in enumerate(c.get("criteria", [])[:6], 1):
                    block = f"""
<b>{i}. {_nn(it.get('title'))}</b><br/>
{_wrap(_nn(it.get('description')), 110)}<br/>
<b>ì¸¡ì •</b>: {_wrap(_nn(it.get('measurement')), 110)}<br/>
<b>ê°€ì¤‘ì¹˜</b>: {_fmt_float(it.get('weight'), 2)}
"""
                    s.append(Paragraph(block, styles["KBody"]))
                    s.append(Spacer(1, 1*mm))

        # --- 5.3 í‰ê°€ ê¸°ì¤€ ì¶œì²˜(í˜ì´ì§€ í‘œê¸° í¬í•¨) ---
        sources = state.get("criteria_sources") or []
        if not sources:
            sources = [{
                "title": "Vara - Crunchbase Company Profile & Funding",
                "tier": "tier2",
                "type": "indirect",
                "reliability": "medium",
                "weight": None,
                "page": None,
                "url": None,
                "publisher": "Crunchbase"
            }]
        s.append(Paragraph("5.3 í‰ê°€ ê¸°ì¤€ ì¶œì²˜", styles["KSubTitle"]))
        for src in sources[:40]:
            title = _nn(src.get("title"))
            tier = _nn(src.get("tier"))
            etype = _nn(src.get("type"))
            rel = _nn(src.get("reliability"))
            wgt = _fmt_float(src.get("weight"), 2) if src.get("weight") is not None else "-"
            page = src.get("page")
            page_str = f"{page}ìª½ ì°¸ê³ " if page else "-"
            pub = _nn(src.get("publisher", "-"))
            meta = f"ì¶œì²˜: {title} Â· ë°œí–‰ì²˜: {pub} Â· Tier: {tier} Â· íƒ€ì…: {etype} Â· ì‹ ë¢°ì„±: {rel} Â· ê°€ì¤‘ì¹˜: {wgt} Â· í˜ì´ì§€: {page_str}"
            s.append(Paragraph(f"â€¢ {meta}", styles["KBody"]))
            url = src.get("url")
            if url:
                s.append(Paragraph(_nn(url), styles["KMeta"]))
            s.append(Spacer(1, 1*mm))

        # --- 5.4 RAG íŠ¸ë ˆì´ìŠ¤(ê²€ìƒ‰ ì¿¼ë¦¬ & ê·¼ê±° í˜ì´ì§€) ---
        traces = state.get("criteria_rag_traces")
        if not traces:
            log_text = state.get("criteria_rag_log_text") or ""
            traces = self._parse_rag_logs(log_text) if log_text else []

        if traces:
            s.append(Paragraph("5.4 RAG íŠ¸ë ˆì´ìŠ¤ (ê²€ìƒ‰ ì¿¼ë¦¬ & ê·¼ê±° í˜ì´ì§€)", styles["KSubTitle"]))
            for t in traces[:10]:  # ê³¼ë„í•œ ê¸¸ì´ ë°©ì§€
                cat = _nn(t.get("category"))
                q = _nn(t.get("query"))
                s.append(Paragraph(f"<b>ì¹´í…Œê³ ë¦¬:</b> {cat}", styles["KBody"]))
                s.append(Paragraph(f"<b>ê²€ìƒ‰ ì¿¼ë¦¬:</b> {q}", styles["KMeta"]))

                matches = t.get("matches") or []
                if matches:
                    s.append(Paragraph("ê·¼ê±° í˜ì´ì§€(ìƒìœ„):", styles["KHead3"]))
                    # í‘œë¡œ ë³´ì—¬ì£¼ë˜ ì…€ì€ Paragraphë¡œ ê°ì‹¸ CJK ì¤„ë°”ê¿ˆ
                    rows = [[Paragraph("í˜ì´ì§€", styles["KCell"]), Paragraph("ë°œì·Œ", styles["KCell"])]]
                    for m in matches[:5]:
                        page = _nn(m.get("page"))
                        snippet = _wrap(_nn(m.get("snippet")), 90)
                        rows.append([Paragraph(str(page), styles["KCell"]), Paragraph(snippet, styles["KCell"])])
                    tbl = self._table(rows, [18*mm, 122*mm], head=True)
                    s.append(KeepTogether([tbl, Spacer(1, 2*mm)]))

                criteria = t.get("generated_criteria") or []
                if criteria:
                    s.append(Paragraph("ìƒì„±ëœ ê¸°ì¤€:", styles["KHead3"]))
                    for i, c in enumerate(criteria[:8], 1):
                        s.append(Paragraph(f"â€¢ {c}", styles["KBullet"]))
                s.append(Spacer(1, 3*mm))

        return s

    # ---------- RAG ë¡œê·¸ íŒŒì„œ ----------
    def _parse_rag_logs(self, text: str) -> List[Dict]:
        """
        ì›ë¬¸ ë¡œê·¸ í…ìŠ¤íŠ¸ ì˜ˆì‹œ(ì‚¬ìš©ì ì œê³µ í¬ë§·)ë¥¼ íŒŒì‹±í•´ êµ¬ì¡°í™”:
        ğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: ...
        ğŸ“œ ê²€ìƒ‰ëœ ì¡°í•­: 10ê°œ
           [1] Page 16: ...
           [2] Page 18: ...
        âœ… ì •í™•ë„ ê²€ì¦ í‰ê°€ ê¸°ì¤€:
           ìƒì„±ëœ ê¸°ì¤€: 6ê°œ
           1. ...
           2. ...
        (ì¹´í…Œê³ ë¦¬ë³„ ë°˜ë³µ)
        """
        traces: List[Dict] = []
        # ë¸”ë¡ì„ '======================================================================' ë¡œ ë‚˜ëˆ ë„ ë˜ì§€ë§Œ
        # ì•ˆì „í•˜ê²Œ 'ğŸ” ê²€ìƒ‰ ì¿¼ë¦¬:'ë¥¼ ê¸°ì¤€ìœ¼ë¡œ split
        blocks = re.split(r"\n(?=ğŸ”\s*ê²€ìƒ‰ ì¿¼ë¦¬:)", text)
        for blk in blocks:
            blk = blk.strip()
            if not blk:
                continue
            m_q = re.search(r"ğŸ”\s*ê²€ìƒ‰\s*ì¿¼ë¦¬:\s*(.+)", blk)
            query = m_q.group(1).strip() if m_q else ""

            # ì¹´í…Œê³ ë¦¬ëª…ì€ 'âœ… XXX í‰ê°€ ê¸°ì¤€' ë¼ì¸ì—ì„œ ìº¡ì²˜
            m_cat = re.search(r"âœ…\s*(.+?)\s*í‰ê°€\s*ê¸°ì¤€", blk)
            category = m_cat.group(1).strip() if m_cat else ""

            # ê²€ìƒ‰ëœ ì¡°í•­ ë¦¬ìŠ¤íŠ¸
            matches = []
            for m in re.finditer(r"\[\d+\]\s*Page\s*(\d+):\s*(.+)", blk):
                page = int(m.group(1))
                snippet = m.group(2).strip()
                matches.append({"page": page, "snippet": snippet})

            # ìƒì„±ëœ ê¸°ì¤€ ëª©ë¡
            criteria = []
            # 'ìƒì„±ëœ ê¸°ì¤€' ì´í›„ì˜ numbered list ì¶”ì¶œ
            sect = re.search(r"ìƒì„±ëœ\s*ê¸°ì¤€[:ï¼š]\s*\d+ê°œ?(.*)", blk, re.S)
            tail = sect.group(1) if sect else blk
            for m in re.finditer(r"^\s*\d+\.\s*(.+)$", tail, re.M):
                criteria.append(m.group(1).strip())

            traces.append({
                "category": category,
                "query": query,
                "matches": matches,
                "generated_criteria": criteria
            })
        return traces

    # ---------- Widgets ----------
    def _table(
        self,
        data: List[List[str]],
        col_widths: List[float],
        head: bool = False,
        emphasize: Optional[List[Tuple[int, int]]] = None,
        emphasize_color: colors.Color = colors.HexColor("#27ae60"),
    ):
        t = Table(data, colWidths=col_widths, hAlign="LEFT", repeatRows=1 if head else 0)
        t.splitByRow = 1
        base = [
            ("FONTNAME", (0, 0), (-1, -1), self.korean_font),
            ("FONTSIZE", (0, 0), (-1, -1), 10),
            ("ALIGN", (0, 0), (-1, -1), "LEFT"),
            ("VALIGN", (0, 0), (-1, -1), "MIDDLE"),
            ("LEFTPADDING", (0, 0), (-1, -1), 7),
            ("RIGHTPADDING", (0, 0), (-1, -1), 7),
            ("TOPPADDING", (0, 0), (-1, -1), 5),
            ("BOTTOMPADDING", (0, 0), (-1, -1), 5),
            ("GRID", (0, 0), (-1, -1), 0.25, colors.HexColor("#bdc3c7")),
            ("ROWBACKGROUNDS", (0, 1 if head else 0), (-1, -1), [colors.white, colors.HexColor("#f9f9f9")]),
        ]
        if head:
            base += [
                ("BACKGROUND", (0, 0), (-1, 0), colors.HexColor("#3498db")),
                ("TEXTCOLOR", (0, 0), (-1, 0), colors.white),
                ("ALIGN", (0, 0), (-1, 0), "CENTER"),
                ("FONTSIZE", (0, 0), (-1, 0), 10.5),
            ]
        if emphasize:
            for (r, c) in emphasize:
                base += [
                    ("TEXTCOLOR", (c, r), (c, r), emphasize_color),
                    ("FONTSIZE", (c, r), (c, r), 13),
                    ("FONTNAME", (c, r), (c, r), self.korean_font),
                ]
        t.setStyle(TableStyle(base))
        return t

    def _bar_chart(self, labels: List[str], values: List[float], height: int = 140):
        width = 420
        d = Drawing(width, height)
        bc = VerticalBarChart()
        bc.x = 40; bc.y = 20
        bc.height = height - 40; bc.width = width - 80
        bc.data = [values]
        bc.categoryAxis.categoryNames = labels
        bc.categoryAxis.labels.boxAnchor = "ne"; bc.categoryAxis.labels.angle = 20
        bc.barWidth = 15
        bc.valueAxis.valueMin = 0; bc.valueAxis.valueMax = 100; bc.valueAxis.valueStep = 20
        bc.groupSpacing = 12
        bc.bars[0].fillColor = colors.HexColor("#3498db")
        d.add(bc)
        return d
