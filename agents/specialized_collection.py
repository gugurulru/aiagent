# agents/specialized_collection.py

from typing import Dict, List
from datetime import datetime
import uuid
from tavily import TavilyClient
from langchain_openai import ChatOpenAI
import warnings
warnings.filterwarnings('ignore', category=UserWarning)
warnings.filterwarnings('ignore', category=DeprecationWarning)

from state_schema import PipelineState, Document


class SpecializedCollectionAgent:
    """
    ì „ë¬¸ ìë£Œ ìˆ˜ì§‘ ì—ì´ì „íŠ¸
    - í•™ìˆ  ë…¼ë¬¸ (Google Scholar)
    - ê·œì œ ë¬¸ì„œ (FDA, EU DB)
    - ì„ìƒì‹œí—˜ ë°ì´í„°
    """
    
    def __init__(self, tavily_api_key: str, openai_api_key: str):
        self.tavily = TavilyClient(api_key=tavily_api_key)
        self.llm = ChatOpenAI(
            model="gpt-4o-mini",
            api_key=openai_api_key,
            temperature=0
        )
    
    def execute(self, state: PipelineState) -> PipelineState:
        """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
        print("\n" + "="*70)
        print("ğŸ“ [ì „ë¬¸ ìë£Œ ìˆ˜ì§‘ Agent] ì‹œì‘")
        print("="*70)
        
        company_name = state["company_name"]
        domain = state["domain"]
        
        try:
            documents = []
            
            # 1. í•™ìˆ  ë…¼ë¬¸ ê²€ìƒ‰
            academic_docs = self._search_academic(company_name, domain)
            documents.extend(academic_docs)
            
            # 2. ê·œì œ ë¬¸ì„œ ê²€ìƒ‰
            regulatory_docs = self._search_regulatory(company_name, domain)
            documents.extend(regulatory_docs)
            
            # 3. ì„ìƒì‹œí—˜ ë°ì´í„° ê²€ìƒ‰ (ì¶”ê°€)
            clinical_docs = self._search_clinical_trials(company_name, domain)
            documents.extend(clinical_docs)
            
            # 4. ì‹ ë¢°ë„ í‰ê°€
            final_docs = self._assess_reliability(documents)
            
            # 5. í†µê³„ ê³„ì‚°
            stats = self._calculate_statistics(final_docs)
            
            # 6. State ì—…ë°ì´íŠ¸
            state["specialized_collection"] = {
                "status": "completed",
                "documents": final_docs,
                "count": len(final_docs),
                "sources": list(set(doc["source_category"] for doc in final_docs)),
                **stats,
                "error": None
            }
            
            print(f"âœ… ì „ë¬¸ ìë£Œ ìˆ˜ì§‘ ì™„ë£Œ: {len(final_docs)}ê°œ ë¬¸ì„œ")
            print(f"  ğŸ“š í•™ìˆ  ë…¼ë¬¸: {sum(1 for d in final_docs if d['source_category']=='academic')}ê°œ")
            print(f"  ğŸ“‹ ê·œì œ ë¬¸ì„œ: {sum(1 for d in final_docs if d['source_category']=='regulatory')}ê°œ")
            print(f"  ğŸ§ª ì„ìƒì‹œí—˜: {sum(1 for d in final_docs if d['source_category']=='clinical_trial')}ê°œ")
            
        except Exception as e:
            print(f"âŒ ì „ë¬¸ ìë£Œ ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
            state["specialized_collection"] = {
                "status": "failed",
                "documents": [],
                "count": 0,
                "sources": [],
                "sources_breakdown": {},
                "primary_sources_count": 0,
                "secondary_sources_count": 0,
                "newest_date": None,
                "oldest_date": None,
                "recent_documents_count": 0,
                "high_reliability_count": 0,
                "medium_reliability_count": 0,
                "low_reliability_count": 0,
                "average_reliability": 0.0,
                "error": str(e)
            }
            
            state["errors"].append({
                "stage": "specialized_collection",
                "error": str(e),
                "timestamp": datetime.now().isoformat(),
                "recovered": False,
                "traceback": None,
                "impact_on_reliability": "medium"
            })
        
        return state
    
    def _search_academic(self, company_name: str, domain: str) -> List[Dict]:
        """í•™ìˆ  ë…¼ë¬¸ ê²€ìƒ‰ (Tavilyë¡œ Scholar ê²€ìƒ‰)"""
        print(f"ğŸ”¬ í•™ìˆ  ë…¼ë¬¸ ê²€ìƒ‰ ì¤‘: {company_name}")
        
        # âœ… ì¿¼ë¦¬ ì¦ê°€: 2ê°œ â†’ 8ê°œ
        queries = [
            f"{company_name} AI {domain} clinical validation study",
            f"{company_name} algorithm accuracy peer reviewed",
            f"{company_name} {domain} machine learning research",
            f"{company_name} diagnostic accuracy study",
            f"{company_name} {domain} clinical trial results",
            f"{company_name} AI medical imaging validation",
            f"{company_name} {domain} retrospective study",
            f"{company_name} algorithm performance evaluation",
        ]
        
        all_docs = []
        
        for query in queries:
            try:
                # Tavilyë¡œ Scholar ê²€ìƒ‰ (ë„ë©”ì¸ ì œí•œ)
                response = self.tavily.search(
                    query=query,
                    search_depth="advanced",
                    max_results=5,  # âœ… 3 â†’ 5ë¡œ ì¦ê°€
                    include_domains=["scholar.google.com", "pubmed.ncbi.nlm.nih.gov", "arxiv.org"]
                )
                
                for result in response.get("results", []):
                    doc = {
                        "id": f"spec_{uuid.uuid4().hex[:8]}",
                        "url": result.get("url", ""),
                        "title": result.get("title", ""),
                        "content": result.get("raw_content", result.get("content", "")),
                        "excerpt": result.get("content", "")[:200],
                        "source_type": "primary",  # í•™ìˆ  ë…¼ë¬¸ì€ 1ì°¨ ì¶œì²˜
                        "source_category": "academic",
                        "publisher": self._extract_publisher(result.get("url", "")),
                        "author": None,
                        "date": None,  # ì¶”ì¶œ í•„ìš”
                        "age_days": 0,
                        "is_recent": False,
                        "reliability": "high",  # í•™ìˆ  ë…¼ë¬¸ì€ ê¸°ë³¸ high
                        "reliability_score": 0.9,
                        "reliability_reasons": ["í•™ìˆ  ë…¼ë¬¸", "ë™ë£Œ ê²€í† "],
                        "evidence_tier": "tier1",
                        "is_verified": False,
                        "verified_by": [],
                        "collected_by": "specialized_collection",
                        "collected_at": datetime.now().isoformat()
                    }
                    all_docs.append(doc)
                
                print(f"  âœ“ '{query[:50]}...' â†’ {len(response.get('results', []))}ê°œ")
                
            except Exception as e:
                print(f"  âœ— '{query[:50]}...' ì‹¤íŒ¨: {str(e)}")
                continue
        
        print(f"ğŸ“š í•™ìˆ  ë…¼ë¬¸ ì´ {len(all_docs)}ê°œ ìˆ˜ì§‘")
        return all_docs
    
    def _search_regulatory(self, company_name: str, domain: str) -> List[Dict]:
        """ê·œì œ ë¬¸ì„œ ê²€ìƒ‰"""
        print(f"ğŸ“‹ ê·œì œ ë¬¸ì„œ ê²€ìƒ‰ ì¤‘: {company_name}")
        
        # âœ… ì¿¼ë¦¬ ì¦ê°€: 2ê°œ â†’ 6ê°œ
        queries = [
            f"{company_name} FDA approval CE mark",
            f"{company_name} EU MDR medical device",
            f"{company_name} FDA 510k clearance",
            f"{company_name} CE marking certificate",
            f"{company_name} medical device regulation approval",
            f"{company_name} regulatory submission documentation",
        ]
        
        all_docs = []
        
        for query in queries:
            try:
                response = self.tavily.search(
                    query=query,
                    search_depth="advanced",
                    max_results=10,  # âœ… 3 â†’ 5ë¡œ ì¦ê°€
                    include_domains=["fda.gov", "ec.europa.eu", "ema.europa.eu"]
                )
                
                for result in response.get("results", []):
                    doc = {
                        "id": f"spec_{uuid.uuid4().hex[:8]}",
                        "url": result.get("url", ""),
                        "title": result.get("title", ""),
                        "content": result.get("raw_content", result.get("content", "")),
                        "excerpt": result.get("content", "")[:200],
                        "source_type": "primary",
                        "source_category": "regulatory",
                        "publisher": "FDA" if "fda.gov" in result.get("url", "") else "EU",
                        "author": None,
                        "date": None,
                        "age_days": 0,
                        "is_recent": False,
                        "reliability": "high",
                        "reliability_score": 0.95,
                        "reliability_reasons": ["ê·œì œ ê¸°ê´€ ê³µì‹ ë¬¸ì„œ", "1ì°¨ ì¶œì²˜"],
                        "evidence_tier": "tier1",
                        "is_verified": False,
                        "verified_by": [],
                        "collected_by": "specialized_collection",
                        "collected_at": datetime.now().isoformat()
                    }
                    all_docs.append(doc)
                
                print(f"  âœ“ '{query[:50]}...' â†’ {len(response.get('results', []))}ê°œ")
                
            except Exception as e:
                print(f"  âœ— '{query[:50]}...' ì‹¤íŒ¨: {str(e)}")
                continue
        
        print(f"ğŸ“‹ ê·œì œ ë¬¸ì„œ ì´ {len(all_docs)}ê°œ ìˆ˜ì§‘")
        return all_docs
    
    def _search_clinical_trials(self, company_name: str, domain: str) -> List[Dict]:
        """ì„ìƒì‹œí—˜ ë°ì´í„° ê²€ìƒ‰ (ì¶”ê°€)"""
        print(f"ğŸ§ª ì„ìƒì‹œí—˜ ë°ì´í„° ê²€ìƒ‰ ì¤‘: {company_name}")
        
        queries = [
            f"{company_name} clinical trial {domain}",
            f"{company_name} clinicaltrials.gov study",
            f"{company_name} {domain} trial results",
            f"{company_name} multicenter trial",
        ]
        
        all_docs = []
        
        for query in queries:
            try:
                response = self.tavily.search(
                    query=query,
                    search_depth="advanced",
                    max_results=5,
                    include_domains=["clinicaltrials.gov", "who.int", "nih.gov"]
                )
                
                for result in response.get("results", []):
                    doc = {
                        "id": f"spec_{uuid.uuid4().hex[:8]}",
                        "url": result.get("url", ""),
                        "title": result.get("title", ""),
                        "content": result.get("raw_content", result.get("content", "")),
                        "excerpt": result.get("content", "")[:200],
                        "source_type": "primary",
                        "source_category": "clinical_trial",
                        "publisher": "ClinicalTrials.gov" if "clinicaltrials.gov" in result.get("url", "") else "WHO",
                        "author": None,
                        "date": None,
                        "age_days": 0,
                        "is_recent": False,
                        "reliability": "high",
                        "reliability_score": 0.92,
                        "reliability_reasons": ["ì„ìƒì‹œí—˜ ë“±ë¡ ë°ì´í„°", "1ì°¨ ì¶œì²˜"],
                        "evidence_tier": "tier1",
                        "is_verified": False,
                        "verified_by": [],
                        "collected_by": "specialized_collection",
                        "collected_at": datetime.now().isoformat()
                    }
                    all_docs.append(doc)
                
                print(f"  âœ“ '{query[:50]}...' â†’ {len(response.get('results', []))}ê°œ")
                
            except Exception as e:
                print(f"  âœ— '{query[:50]}...' ì‹¤íŒ¨: {str(e)}")
                continue
        
        print(f"ğŸ§ª ì„ìƒì‹œí—˜ ë°ì´í„° ì´ {len(all_docs)}ê°œ ìˆ˜ì§‘")
        return all_docs
    
    def _extract_publisher(self, url: str) -> str:
        """URLì—ì„œ ë°œí–‰ì²˜ ì¶”ì¶œ"""
        if "pubmed" in url:
            return "PubMed"
        elif "scholar.google" in url:
            return "Google Scholar"
        elif "arxiv" in url:
            return "arXiv"
        elif "nature.com" in url:
            return "Nature"
        elif "clinicaltrials.gov" in url:
            return "ClinicalTrials.gov"
        else:
            return "Academic"
    
    def _assess_reliability(self, documents: List[Dict]) -> List[Document]:
        """ì‹ ë¢°ë„ ì¬í‰ê°€"""
        # ì „ë¬¸ ìë£ŒëŠ” ì´ë¯¸ ë†’ì€ ì‹ ë¢°ë„ì§€ë§Œ ìµœì‹ ì„± ì²´í¬
        for doc in documents:
            if doc["date"]:
                try:
                    doc_date = datetime.fromisoformat(doc["date"])
                    age_days = (datetime.now() - doc_date).days
                    doc["age_days"] = age_days
                    doc["is_recent"] = age_days <= 180
                except:
                    doc["age_days"] = 999
                    doc["is_recent"] = False
        
        return documents
    
    def _calculate_statistics(self, documents: List[Document]) -> Dict:
        """í†µê³„ ê³„ì‚° (web_collectionê³¼ ë™ì¼)"""
        stats = {
            "sources_breakdown": {},
            "primary_sources_count": 0,
            "secondary_sources_count": 0,
            "newest_date": None,
            "oldest_date": None,
            "recent_documents_count": 0,
            "high_reliability_count": 0,
            "medium_reliability_count": 0,
            "low_reliability_count": 0,
            "average_reliability": 0.0
        }
        
        if not documents:
            return stats
        
        for doc in documents:
            cat = doc["source_category"]
            stats["sources_breakdown"][cat] = stats["sources_breakdown"].get(cat, 0) + 1
            
            if doc["source_type"] == "primary":
                stats["primary_sources_count"] += 1
            else:
                stats["secondary_sources_count"] += 1
            
            if doc["is_recent"]:
                stats["recent_documents_count"] += 1
            
            if doc["reliability"] == "high":
                stats["high_reliability_count"] += 1
            elif doc["reliability"] == "medium":
                stats["medium_reliability_count"] += 1
            else:
                stats["low_reliability_count"] += 1
        
        dates = [doc["date"] for doc in documents if doc["date"]]
        if dates:
            stats["newest_date"] = max(dates)
            stats["oldest_date"] = min(dates)
        
        if len(documents) > 0:
            avg_rel = sum(doc["reliability_score"] for doc in documents) / len(documents)
            stats["average_reliability"] = round(avg_rel, 2)
        
        return stats